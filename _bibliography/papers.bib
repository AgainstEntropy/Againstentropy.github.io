---
---

@string{aps = {American Physical Society,}}

@inproceedings{wang2023nlosTrack,
  bibtex_show = {true},
  abbr        = {CVPR},
  author      = {Wang, Yihao and Wang, Zhigang and Zhao, Bin and Wang, Dong and Chen, Mulin and Li, Xuelong},
  abstract    = {Non-line-of-sight (NLOS) tracking has drawn increasing attention in recent years, due to its ability to detect object motion out of sight. Most previous works on NLOS tracking rely on active illumination, e.g., laser, and suffer from high cost and elaborate experimental conditions. Besides, these techniques are still far from practical application due to oversimplified settings. In contrast, we propose a purely passive method to track a person walking in an invisible room by only observing a relay wall, which is more in line with real application scenarios, e.g., security. To excavate imperceptible changes in videos of the relay wall, we introduce difference frames as an essential carrier of temporal-local motion messages. In addition, we propose PAC-Net, which consists of alternating propagation and calibration, making it capable of leveraging both dynamic and static messages on a frame-level granularity. To evaluate the proposed method, we build and publish the first dynamic passive NLOS tracking dataset, NLOS-Track, which fills the vacuum of realistic NLOS datasets. NLOS-Track contains thousands of NLOS video clips and corresponding trajectories. Both real-shot and synthetic data are included. Our codes and dataset are available at https://againstentropy.github.io/NLOS-Track/.},
  title       = {Propagate And Calibrate: Real-time Passive Non-line-of-sight Tracking},
  booktitle   = {CVPR},
  year        = {2023},
  arxiv       = {2303.11791},
  url         = {https://openreview.net/forum?id=eLWegLwpZJ},
  html        = {https://againstentropy.github.io/NLOS-Track/},
  preview     = {render-scene.svg},
  dimensions  = {true},
  selected    = {true},
}
